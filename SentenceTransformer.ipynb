{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------------------------\n",
        "#----------------------------- BEGIN CV DATA  -----------------------------\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "# !!!  !!!  !!!  !!!  !!!  !!!  !!!  !!!  !!!  !!!  !!!  !!!  !!!  !!!  !!!  !!!\n",
        "#########>>>>#########>>>>#########>>>>#########>>>>#########>>>>#########>>>>\n",
        "# ------------- BEFORE RUNNING THIS CODE - YOU NEED TO SAVE -------------\n",
        "# -------- THE CVS.zip in Google Drive-main page. --------\n",
        "#########>>>>#########>>>>#########>>>>#########>>>>#########>>>>#########>>>>\n",
        "# !!!  !!!  !!!  !!!  !!!  !!!  !!!  !!!  !!!  !!!  !!!  !!!  !!!  !!!  !!!  !!!\n",
        "\n",
        "\n",
        "# The code:\n",
        "#  [1] Creates in the google drive a couple of folders and files:\n",
        "#       [i] Main Folder named CVS\n",
        "#           \"../gdrive/My Drive/CVS\"\n",
        "#           Contains all folthers and .csv files as answers\n",
        "#      [ii] CVs - \"../gdrive/My Drive/CVS/CVs\"\n",
        "#           Contains all the CVs.docx\n",
        "#     [iii] Results - \"../gdrive/My Drive/CVS/Results\"\n",
        "#           Contains new colored CVs.docx\n",
        " \n",
        "#  [2] With FOR LOOP:\n",
        "#       [i] converts all files from type doc to docx\n",
        "#      [ii] uses XML to read the word file and creates:\n",
        "#           a dictionary(for searhing) and a list of all the lines(for model)\n",
        "\n",
        "#  [3] Uses a sentence-transformers model 'all-MiniLM-L6-v1' that maps\n",
        "#      sentences & paragraphs to a vector space and can be used for tasks like\n",
        "#      clustering or semantic search.\n",
        "#      If It won't work properly => change to  'all-MiniLM-L12-v2'\n",
        "\n",
        "#  [4] Finds needed information+colors it and saves as new word [in 'Results']\n",
        "\n",
        "#  [5] Prints the answer + saves as csv file and downloads it.\n"
      ],
      "metadata": {
        "id": "5JEfxNAzIuId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Helping stuff\n",
        "# %-------------------------------%\n",
        "# --------- Helping stuff ---------\n",
        "# %-------------------------------%\n",
        "\n",
        "# Making mount with the google drive\n",
        "import google.colab\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "# AutoComplete\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "## Will display all of the packages installed in the virtual environment\n",
        "# !python -m pip list"
      ],
      "metadata": {
        "id": "xsfh60tr_Exc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import and install if needed\n",
        "# %----------------------------------------------%\n",
        "# --------- Import and install if needed ---------\n",
        "# %-----------------------------------------------%\n",
        "\n",
        "![ ! -f \"pip_installed\" ] && pip -q install --upgrade google-api-python-client\n",
        "\n",
        "![ ! -f \"pip_installed\" ] && pip -q install --upgrade jedi==0.17.2\n",
        "\n",
        "![ ! -f \"pip_installed\" ] && pip -q install --upgrade textract\n",
        "import textract\n",
        "\n",
        "![ ! -f \"pip_installed\" ] && pip -q install --upgrade python-docx\n",
        "import docx\n",
        "from docx import Document\n",
        "from docx.shared import Pt\n",
        "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
        "\n",
        "![ ! -f \"pip_installed\" ] && pip -q install --upgrade aspose.words\n",
        "import aspose.words as aw\n",
        "\n",
        "![ ! -f \"pip_installed\" ] && pip -q install --upgrade docx2python\n",
        "import docx2python\n",
        "from docx2python import docx2python\n",
        "\n",
        "#### FOR NETWORK\n",
        "!pip install sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "![ ! -f \"pip_installed\" ] && pip -q install --upgrade umap-learn\n",
        "# !pip install umap-learn\n",
        "import umap\n",
        "\n",
        "![ ! -f \"pip_installed\" ] && pip -q install --upgrade altair-viewer\n",
        "# !pip install altair-viewer\n",
        "import altair as alt\n",
        "import altair_viewer\n",
        "\n",
        "\n",
        "try:\n",
        "    from xml.etree.cElementTree import XML\n",
        "except ImportError:\n",
        "    from xml.etree.ElementTree import XML\n",
        "\n",
        "import zipfile\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import csv\n",
        "import io\n",
        "import os\n",
        "import re  # to find stuff in a string\n",
        "import itertools\n",
        "import requests    \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "from google.colab import files\n",
        "\n",
        "# import win32com.client\n",
        "# from docx.api import Document"
      ],
      "metadata": {
        "id": "KCDZxvYg7QO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Unzipping the CVs\n",
        "# %-----------------------------------%\n",
        "# --------- Unzipping the CVs ---------\n",
        "# %-----------------------------------%\n",
        "\n",
        "# specifying the zip file name\n",
        "file_name = \"../gdrive/My Drive/CVS.zip\"\n",
        "\n",
        "# opening the zip file in READ mode\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "    # printing all the contents of the zip file\n",
        "    # zip.printdir()\n",
        "\n",
        "    # extract specific files\n",
        "    zip.extract(\"CVS/CVs.zip\", \"../gdrive/My Drive\")\n",
        "    ZipFile(\"../gdrive/My Drive/CVS/CVs.zip\", 'r').extractall(\"../gdrive/My Drive/CVS\")\n",
        "    zip.close()\n",
        "os.remove(\"../gdrive/My Drive/CVS/CVs.zip\")"
      ],
      "metadata": {
        "id": "PaD36q5AQqkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## remove\n",
        "# import shutil\n",
        "# shutil.rmtree(\"../gdrive/My Drive/CVS\")\n",
        "# shutil.rmtree(\"../gdrive/My Drive/CVS/CVs\")"
      ],
      "metadata": {
        "id": "uJ8Bt9VkTZy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title # Change_doc_to_docx ##\n",
        "# %--------------------------------------------------------------------------%\n",
        "# INPUT: dir_path, file_name, doc_path  OUTPUT: Saved as docx+returns new path\n",
        "# %--------------------------------------------------------------------------%\n",
        "\n",
        "def change_doc_to_docx(dir_path, file_name, doc_path):\n",
        "    input = aw.Document(doc_path)\n",
        "    output = aw.Document()\n",
        "    output.remove_all_children()\n",
        "    output.append_document(input, aw.ImportFormatMode.KEEP_SOURCE_FORMATTING)\n",
        "    \n",
        "    index_type = file_name.find('.') + 1\n",
        "    doc_path = os.path.join(dir_path, file_name[:index_type]) + 'docx'\n",
        "    output.save(doc_path)\n",
        "\n",
        "    return doc_path"
      ],
      "metadata": {
        "id": "_agX4mOIndzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Remove function#\n",
        "# %-------------------------------------------------------------%\n",
        "# Input: File path   Output: Dictionary of the text:  (line:text)\n",
        "# %-------------------------------------------------------------%\n",
        "\n",
        "def remove_t(paragraph, times, replace):\n",
        "    for _ in range(times):\n",
        "        paragraph = paragraph.replace(replace, \" \")\n",
        "    return paragraph"
      ],
      "metadata": {
        "id": "rSjuj6ievDTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title # YES (Version.1.2 - USING XML - GET DICTIOANRY + LIST) #\n",
        "# %----------------------------------------------------------------%\n",
        "# Input: File path   Output: List+Dictionary of the text (line:text)\n",
        "# %----------------------------------------------------------------%\n",
        "\n",
        "def get_docx_text_to_list_dict_XML(path):\n",
        "    \"\"\"Take the path of a docx file as argument, return the text in unicode.\"\"\"\n",
        "    WORD_NAMESPACE = '{http://schemas.openxmlformats.org/wordprocessingml/2006/main}'\n",
        "    PARA = WORD_NAMESPACE + 'p'\n",
        "    TEXT = WORD_NAMESPACE + 't'\n",
        "    # PAGE = WORD_NAMESPACE + 'lastRenderedPageBreak'\n",
        "\n",
        "    document = zipfile.ZipFile(path)\n",
        "    xml_content = document.read('word/document.xml').decode('utf-8')\n",
        "    document.close()\n",
        "    tree = XML(xml_content)\n",
        "    \n",
        "    lines = []\n",
        "    docx_dict = {}\n",
        "\n",
        "    for indx, paragraph in enumerate(tree.getiterator(PARA), start=1):\n",
        "        texts = [n.text for n in paragraph.getiterator(TEXT) if n.text]        \n",
        "        if texts:\n",
        "            adding = ''.join(texts).lower()\n",
        "\n",
        "            # cleaning\n",
        "            if \"\\t\" in adding:\n",
        "                adding = remove_t(adding, adding.count(\"\\t\"), \"\\t\")\n",
        "            if \"_\" in adding:\n",
        "                adding = remove_t(adding, adding.count(\"_\"), \"_\")\n",
        "            adding = adding.rstrip()\n",
        "\n",
        "            if len(adding) != 0:\n",
        "                lines.append(adding)\n",
        "                docx_dict[indx] = adding\n",
        "    return docx_dict, lines"
      ],
      "metadata": {
        "id": "I10ZuXrflbLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title NOPE (Version.2.2 - USING docx2python - GET DICTIOANRY + LIST)\n",
        "# %----------------------------------------------------------------%\n",
        "# Input: File path   Output: List+Dictionary of the text (line:text)\n",
        "# %----------------------------------------------------------------%\n",
        "\n",
        "def get_docx_text_to_list_dict_docx2python(path):    \n",
        "    doc = docx2python(path)\n",
        "    docx_dict = {}\n",
        "    lines = []\n",
        "    \n",
        "    # 3 times itertools cause there are 3 levels\n",
        "    tmp = list(itertools.chain(*doc.document))\n",
        "    tmp = list(itertools.chain(*tmp))\n",
        "    tmp = list(itertools.chain(*tmp))\n",
        "    indx = 1\n",
        "\n",
        "    for paragraph in tmp:\n",
        "        # paragraph = paragraph.rstrip()\n",
        "        if paragraph:\n",
        "            # cleaning\n",
        "            if \"\\t\" in paragraph:\n",
        "                paragraph = remove_t(paragraph, paragraph.count(\"\\t\"), \"\\t\")\n",
        "            if \"_\" in paragraph:\n",
        "                paragraph = remove_t(paragraph, paragraph.count(\"_\"), \"_\")\n",
        "            paragraph = paragraph.rstrip()\n",
        "\n",
        "            if len(paragraph) != 0:\n",
        "                lines.append(paragraph.lower())                \n",
        "                if \"--\" in paragraph[0:3]:\n",
        "                    if indx not in docx_dict:\n",
        "                        docx_dict[indx] = paragraph\n",
        "                    else:                    \n",
        "                        docx_dict[indx] = docx_dict[indx] + '  ' + paragraph\n",
        "                else:            \n",
        "                    indx += 1\n",
        "                    docx_dict[indx] = paragraph\n",
        "                    indx += 1                \n",
        "                \n",
        "    return docx_dict, lines"
      ],
      "metadata": {
        "id": "7VFyiFgMg_16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Example for myself - get_docx_text_to_dict\n",
        "# %-------------------------------------------------------------------%\n",
        "#---- Example for myself to find what is better XML or docx2python ----\n",
        "# %-------------------------------------------------------------------%\n",
        "\n",
        "d = \"../gdrive/My Drive/CVS/CVs/\"\n",
        "\n",
        "# p = 'Data-Analyst-Resume-Example-MSWord-Download.docx'\n",
        "# p = 'Bank-Teller-Resume-Sample-MSWord-Download.docx'\n",
        "p = 'Graphic-Designer-Resume-Sample-MSWord-Download.docx'\n",
        "# p = 'Electrician-Resume-Sample-MSWord-Download.docx'\n",
        "# p = 'Retail-Manager-Resume-Sample-MSWord-Download.docx'\n",
        "\n",
        "# return docx_dict, lines\n",
        "\n",
        "# d1, l1 = get_docx_text_to_list_dict_XML((d+p))\n",
        "d2, l2 = get_docx_text_to_list_dict_docx2python((d+p))\n",
        "\n",
        "# d2\n",
        "\n",
        "#########>>>>#########>>>>#########>>>>#########>>>>#########>>>>\n",
        "# >>>>>>> get_docx_text_to_list_dict_XML is the best # <<<<<<<\n",
        "#########>>>>#########>>>>#########>>>>#########>>>>#########>>>>"
      ],
      "metadata": {
        "id": "kfZfYZXpXW5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %-------------------------------------------------------------------%\n",
        "#---- FOR LOOP that builds:   [1] docx_content = {}  [2] lines = [] ----\n",
        "# %-------------------------------------------------------------------%\n",
        "\n",
        "# LIST OF FILES\n",
        "dir_path = \"../gdrive/My Drive/CVS/CVs\"\n",
        "lines = []\n",
        "docx_content = {}\n",
        "\n",
        "# Iterate directory\n",
        "for file_name in os.listdir(dir_path):    \n",
        "    path_to_doc = os.path.join(dir_path, file_name)\n",
        "\n",
        "    # check if current file is a doc\n",
        "    if file_name.endswith(\".doc\"):\n",
        "        path_to_doc = change_doc_to_docx(dir_path, file_name, path_to_doc)\n",
        "\n",
        "    # check if current path is a file - then build dict+list:\n",
        "    if os.path.isfile(path_to_doc):\n",
        "        # tmp_dict, tmp_lines = get_docx_text_to_list_dict_XML(path_to_doc)\n",
        "        tmp_dict, tmp_lines = get_docx_text_to_list_dict_docx2python(path_to_doc)\n",
        "\n",
        "        lines += tmp_lines\n",
        "        docx_content[file_name] = tmp_dict"
      ],
      "metadata": {
        "id": "dK_cliLN7hc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(lines)\n",
        "# lines"
      ],
      "metadata": {
        "id": "Ec8YHIt_hWeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Example for myself - docx_content\n",
        "# %--------------------------%\n",
        "#----- Example for myself ----\n",
        "# %---------------------------%\n",
        "\n",
        "# p = 'School-Bus-Driver-Resume-Sample-MSWord-Download.docx'\n",
        "# p = 'Sales-Associate-Resume-Sample-MSWord-Download (1).docx'\n",
        "# p = 'Nanny-Resume-Sample-MSWord-Download.docx'\n",
        "p = 'Bank-Teller-Resume-Sample-MSWord-Download.docx'\n",
        "# p = 'combination-janitor-resume-sample-MSWord-download.docx'\n",
        "# p = 'Electrician-Resume-Sample-MSWord-Download.docx'\n",
        "\n",
        "a = docx_content[p].values()\n",
        "# a"
      ],
      "metadata": {
        "id": "tI76rDQC2unp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %---------------------------------------------------%\n",
        "# ----- USING A MODEL named - 'all-MiniLM-L12-v2' -----\n",
        "# ---------- sentence -> vector in R^n ----------\n",
        "# %---------------------------------------------------%\n",
        "\n",
        "# model = SentenceTransformer('all-MiniLM-L12-v2')\n",
        "model = SentenceTransformer('all-MiniLM-L6-v1')\n",
        "# embeddings_model = model.encode(lines)\n",
        "## R^n -> R^2"
      ],
      "metadata": {
        "id": "HO897gDOZQtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %----------------------------%\n",
        "# -----  CLASS to design   -----\n",
        "# %----------------------------%\n",
        "\n",
        "class color:\n",
        "  PURPLE = '\\033[95m'\n",
        "  CYAN = '\\033[96m'\n",
        "  DARKCYAN = '\\033[36m'\n",
        "  BLUE = '\\033[94m'\n",
        "  GREEN = '\\033[92m'\n",
        "  YELLOW = '\\033[93m'\n",
        "  RED = '\\033[91m'\n",
        "  BOLD = '\\033[1m'\n",
        "  UNDERLINE = '\\033[4m'\n",
        "  END = '\\033[0m'"
      ],
      "metadata": {
        "id": "eCp4R9q31Ted"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %-----------------------------------------------------------%\n",
        "# -----  importing WD_COLOR_INDEX and defing cos_angle   -----\n",
        "# %-----------------------------------------------------------%\n",
        "\n",
        "from docx.enum.text import WD_COLOR_INDEX\n",
        "gdrive = '../gdrive/My Drive/CVS/'\n",
        "try:\n",
        "    os.mkdir(gdrive+'Results')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "\n",
        "def cos_angle(line,target):\n",
        "    # sentence -> R^n\n",
        "    line = model.encode(line)\n",
        "    target = model.encode(target)\n",
        "    return np.abs(np.inner(line,target) / np.linalg.norm(line) / np.linalg.norm(target))\n",
        "\n",
        "\n",
        "list_we_want = ['name', 'email', 'experience', 'education']"
      ],
      "metadata": {
        "id": "ODdPoIvcy4nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %------------------------------------------------------------------------%\n",
        "# --------------------------------  ANSWER  --------------------------------\n",
        "# -----  For loop that finds - (name, email, education, experience)   -----\n",
        "# %------------------------------------------------------------------------%\n",
        "\n",
        "# with open(gdrive+'cv_details_all-MiniLM-L12-v2.csv', 'w', encoding='utf-8-sig') as file:\n",
        "with open(gdrive+'cv_details_all-MiniLM-L6-v1.csv', 'w', encoding='utf-8-sig') as file:\n",
        "    names_upper = [name.upper() for name in list_we_want]\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(names_upper)\n",
        "\n",
        "    for file_name, dict_chosen_file in docx_content.items():\n",
        "        # create a document to save new colored data\n",
        "        doc = docx.Document()\n",
        "        \n",
        "        d = {'name'                     : [],\n",
        "            'email'                    : [],\n",
        "            'experience'               : [],\n",
        "            'education'                : [],\n",
        "            'additional skills'        : [],\n",
        "            'awards'                   : [],\n",
        "            'licenses and certificates': [],\n",
        "            'languages'                : [],\n",
        "            'rest'                     : [],\n",
        "        }\n",
        "\n",
        "        # the last title\n",
        "        saving = 'rest'\n",
        "\n",
        "        for line_num, line_value in dict_chosen_file.items():\n",
        "            threshold = 0.5\n",
        "            line = line_value              \n",
        "\n",
        "            if 'resume' in line:\n",
        "                where = line.find('resume') - 1\n",
        "                d['name'] = [line[:where]]                        \n",
        "            \n",
        "            elif '@' in line:\n",
        "                match = re.findall(r'[\\w.+-]+@[\\w-]+\\.[\\w.-]+', line)\n",
        "                d['email'] = [match[0]]\n",
        "            \n",
        "            elif cos_angle(line, 'experience') > threshold:\n",
        "                saving = 'experience'\n",
        "            \n",
        "            # cos_angle('elementary teacher', 'teacher') = 0.8646255\n",
        "            elif cos_angle(line, 'education') > threshold \\\n",
        "                and cos_angle(line, 'skills') < 0.8    \\\n",
        "                and cos_angle(line, 'teacher') < 0.8:\n",
        "                  saving = 'education'\n",
        "\n",
        "            elif cos_angle(line, 'additional skills') > threshold:\n",
        "                saving = 'additional skills'\n",
        "            \n",
        "            elif cos_angle(line, 'awards') > threshold:\n",
        "                saving = 'awards'\n",
        "\n",
        "            elif cos_angle(line, 'licenses and certificates') > threshold:\n",
        "                saving = 'licenses and certificates'\n",
        "            \n",
        "            elif cos_angle(line, 'languages') > threshold:\n",
        "                saving = 'languages'\n",
        "            \n",
        "            if len(d['name']) == 0:            \n",
        "                where2 = file_name.lower().find('resume') - 1\n",
        "                tmp_name = file_name[:where2].lower()\n",
        "                if '-' in tmp_name:\n",
        "                    tmp_name = remove_t(tmp_name, tmp_name.count(\"-\"), '-')\n",
        "                if '_' in tmp_name:\n",
        "                    tmp_name = remove_t(tmp_name, tmp_name.count(\"_\"), '_')                \n",
        "                d['name'] = [tmp_name]\n",
        "\n",
        "\n",
        "            d[saving].append(line)\n",
        "\n",
        "            # coloring the file:\n",
        "            # [PINK = name, TURQUOISE = email, YELLOW = experience, BRIGHT_GREEN = education]\n",
        "            if 'resume' in line:\n",
        "                line1 = line[:where]\n",
        "                line2 = line[where:]\n",
        "                p = doc.add_paragraph()\n",
        "                p.style.font.name = 'Arial'\n",
        "                p.style.font.size=Pt(10)\n",
        "                p.paragraph_format.space_after = 1\n",
        "\n",
        "                p.add_run(line1).font.highlight_color = WD_COLOR_INDEX.PINK\n",
        "                p.add_run(line2).font.highlight_color = WD_COLOR_INDEX.AUTO\n",
        "                p.paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "\n",
        "\n",
        "            elif '@' in line:\n",
        "                p = doc.add_paragraph()\n",
        "                p.style.font.name = 'Arial'\n",
        "                p.style.font.size=Pt(10)\n",
        "                p.paragraph_format.space_after = 1\n",
        "                chuncks = re.split(r'([\\w.+-]+@[\\w-]+\\.[\\w.-]+)', line)\n",
        "                p.paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "                for chunck in chuncks:\n",
        "                    if re.fullmatch(r'[\\w.+-]+@[\\w-]+\\.[\\w.-]+', chunck):\n",
        "                        p.add_run(chunck).font.highlight_color = WD_COLOR_INDEX.TURQUOISE\n",
        "                    else:\n",
        "                        p.add_run(chunck).font.highlight_color = WD_COLOR_INDEX.AUTO\n",
        "\n",
        "            elif saving == 'experience':\n",
        "                p = doc.add_paragraph()                \n",
        "                p.paragraph_format.space_after = 1\n",
        "                p.add_run(line).font.highlight_color = WD_COLOR_INDEX.YELLOW\n",
        "\n",
        "            elif saving == 'education':\n",
        "                p = doc.add_paragraph()                \n",
        "                p.paragraph_format.space_after = 1\n",
        "                p.add_run(line).font.highlight_color = WD_COLOR_INDEX.BRIGHT_GREEN\n",
        "\n",
        "            else:\n",
        "                p = doc.add_paragraph()                \n",
        "                p.paragraph_format.space_after = 1\n",
        "                p.add_run(line).font.highlight_color = WD_COLOR_INDEX.AUTO\n",
        "        \n",
        "        add_to_csv = []\n",
        "        for key,value in d.items():\n",
        "            if key in list_we_want:\n",
        "                tmp_val = ' '.join(value)\n",
        "                print(f\"{color.GREEN + key + color.END} = {tmp_val}\")\n",
        "                add_to_csv.append(tmp_val)\n",
        "        print('\\n')\n",
        "        writer.writerow(add_to_csv)\n",
        "        doc.save(gdrive+'Results/'+file_name+'_modified.docx')\n",
        "\n",
        "files.download(gdrive+'cv_details_all-MiniLM-L6-v1.csv')\n",
        "# files.download(gdrive+'cv_details_all-MiniLM-L12-v2.csv')"
      ],
      "metadata": {
        "id": "VgMMdWH6HFjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# files.download(gdrive+'cv_details_all-MiniLM-L6-v1.csv')"
      ],
      "metadata": {
        "id": "VLM1b4oaHhoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Zm78akD9u2F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}